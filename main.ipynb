{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T14:54:46.834254Z",
     "start_time": "2024-06-24T14:54:46.827002Z"
    }
   },
   "id": "5d9d94ffb2e0fa0b",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "pdf_files = [\"2022-sustainability-report.pdf\"]\n",
    "\n",
    "docs = []\n",
    "for pdf in pdf_files:\n",
    "    loader = PyMuPDFLoader(pdf)\n",
    "    loaded_docs = loader.load()\n",
    "    for doc in loaded_docs:\n",
    "        doc.metadata['source'] = pdf\n",
    "        doc.metadata['page'] = doc.metadata.get('page', 1)  \n",
    "    docs.extend(loaded_docs)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T14:56:04.425527Z",
     "start_time": "2024-06-24T14:54:46.837467Z"
    }
   },
   "id": "6b15cfcbe25c3205",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "\n",
    "class GradeDocuments(BaseModel):\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "llm=ChatGroq(groq_api_key=GROQ_API_KEY,\n",
    "             model_name=\"Llama3-8b-8192\", temperature=0)\n",
    "\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "question = \"agent memory\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T14:56:08.445568Z",
     "start_time": "2024-06-24T14:56:04.428247Z"
    }
   },
   "id": "c4ed5b659d4fe5e8",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, it appears that Amazon's agent memory plays a crucial role in reducing veteran suicide by coordinating with the U.S. Department of Veterans Affairs and other organizations. The company's resources are leveraged to support veteran service organizations globally, and initiatives like Program Honor are established to advance suicide prevention efforts.\n",
      "\n",
      "According to the report, Amazon's agent memory is used to:\n",
      "\n",
      "* Assist in reducing veteran suicide by coordinating with the U.S. Department of Veterans Affairs and other organizations.\n",
      "* Provide support to finalists through an accelerator course and technical mentorship.\n",
      "* Grow partnerships with organizations like the Royal British Legion and advance initiatives like Program Honor.\n",
      "\n",
      "(Source: Building a Better Future Together 2022 Amazon Sustainability Report, Page: 64)\n",
      "\n",
      "It is essential to note that the exact details of Amazon's agent memory and its role in reducing veteran suicide are not explicitly stated in the provided context. However, it is clear that the company is committed to supporting veteran service organizations and advancing suicide prevention efforts.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_docs(docs):\n",
    "    formatted_docs = []\n",
    "    for doc in docs:\n",
    "        formatted_doc = f\"{doc.page_content}\\n(Source: {doc.metadata['source']}, Page: {doc.metadata['page']})\"\n",
    "        formatted_docs.append(formatted_doc)\n",
    "    return \"\\n\\n\".join(formatted_docs)\n",
    "\n",
    "rag_prompt = hub.pull(\"rlm/rag-prompt-llama\")\n",
    "citation_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. When answering the question, use the provided context and include citations in the format (Source: [document name], Page: [page number]).\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "    (\"human\", \"Context: {context}\")\n",
    "])\n",
    "\n",
    "rag_chain = citation_prompt | llm | StrOutputParser()\n",
    "\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T14:56:12.251820Z",
     "start_time": "2024-06-24T14:56:08.446660Z"
    }
   },
   "id": "1ea9fa4e8d607731",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "GradeHallucinations(binary_score='yes')"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Hallucination Grader\n",
    "\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n",
    "     Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T14:56:13.167549Z",
     "start_time": "2024-06-24T14:56:12.254058Z"
    }
   },
   "id": "b38d667859299c5f",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "GradeAnswer(binary_score='no')"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Answer Grader\n",
    "\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n \n",
    "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "answer_grader = answer_prompt | structured_llm_grader\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T14:56:13.714748Z",
     "start_time": "2024-06-24T14:56:13.168734Z"
    }
   },
   "id": "8307ec28bd181ab1",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'Here\\'s a rewritten version of the question that\\'s optimized for vectorstore retrieval:\\n\\n\"What are the key concepts related to an agent\\'s cognitive abilities, particularly in terms of information storage and retrieval?\"\\n\\nThis rewritten question aims to capture the underlying semantic intent of the original question, which appears to be about an agent\\'s ability to store and retrieve information. By using more specific and technical terms like \"cognitive abilities\", \"information storage\", and \"retrieval\", the question becomes more precise and targeted, making it easier for a vectorstore to retrieve relevant documents and concepts.\\n\\nAdditionally, the rewritten question uses a more formal and technical tone, which is more suitable for a vectorstore retrieval system. This can help to improve the accuracy and relevance of the search results.'"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question Re-writer\n",
    "\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"question\": question})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T14:56:14.442752Z",
     "start_time": "2024-06-24T14:56:13.715981Z"
    }
   },
   "id": "120ae65ea9ab5fbb",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]\n",
    "    citations: List[str]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T14:56:14.451100Z",
     "start_time": "2024-06-24T14:56:14.443784Z"
    }
   },
   "id": "bf77c0d1dc0cf284",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### Nodes\n",
    "\n",
    "def retrieve(state):\n",
    "\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.get_relevant_documents(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    context = format_docs(documents)\n",
    "    generation = rag_chain.invoke({\"context\": context, \"question\": question})\n",
    "    \n",
    "    citations = []\n",
    "    for doc in documents:\n",
    "        if f\"(Source: {doc.metadata['source']}, Page: {doc.metadata['page']})\" in generation:\n",
    "            citations.append({\n",
    "                \"source\": doc.metadata['source'],\n",
    "                \"page\": doc.metadata['page']+1\n",
    "            })\n",
    "    \n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation, \"citations\": citations}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "    if not filtered_documents:\n",
    "            print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\")\n",
    "            return \"transform_query\"\n",
    "    else:\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T14:56:14.472337Z",
     "start_time": "2024-06-24T14:56:14.452106Z"
    }
   },
   "id": "8d50bbc35f918d6c",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
    "\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"transform_query\",\n",
    "    },\n",
    ")\n",
    "app = workflow.compile()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T14:56:14.485930Z",
     "start_time": "2024-06-24T14:56:14.473429Z"
    }
   },
   "id": "6fb3269528bcc71e",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "\"Finished running 'retrieve':\"\n",
      "'\\n---\\n'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "\"Finished running 'grade_documents':\"\n",
      "'\\n---\\n'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "\"Finished running 'generate':\"\n",
      "'\\n---\\n'\n",
      "Generation:\n",
      "Based on the provided context, it appears that Amazon is prioritizing recyclability and carbon impact in their packaging and waste management strategies. Here are some key points:\n",
      "\n",
      "1. Recyclable paper-based packaging: Amazon's recyclable paper-based packaging helps customers divert waste from landfills (Source: 2022-sustainability-report.pdf, Page: 32).\n",
      "2. Reducing packaging waste: Amazon is working to reduce packaging waste by sending more materials back into the circular economy loop (Source: 2022-sustainability-report.pdf, Page: 29).\n",
      "3. Circular economy: Amazon is committed to transitioning to a circular economy where waste is eliminated, resources are circulated, and nature is regenerated (Source: 2022-sustainability-report.pdf, Page: 29).\n",
      "4. Carbon impact: By reducing packaging waste and increasing recyclability, Amazon is also reducing its carbon impact and contributing to a more sustainable future.\n",
      "\n",
      "Overall, Amazon's focus on recyclability and carbon impact is an important step towards reducing waste and promoting sustainability in their operations and supply chain.\n",
      "\n",
      "Citations:\n",
      "- 2022-sustainability-report.pdf, Page: 33\n",
      "- 2022-sustainability-report.pdf, Page: 33\n",
      "- 2022-sustainability-report.pdf, Page: 33\n",
      "- 2022-sustainability-report.pdf, Page: 30\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "inputs = {\"question\": \"Tell me about Prioritizing Recyclability and Carbon Impact?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running '{key}':\")\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "print(\"Generation:\")\n",
    "print(value[\"generation\"])\n",
    "print(\"\\nCitations:\")\n",
    "for citation in value[\"citations\"]:\n",
    "    print(f\"- {citation['source']}, Page: {citation['page']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T14:56:19.564717Z",
     "start_time": "2024-06-24T14:56:14.489547Z"
    }
   },
   "id": "c5d139218576db29",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "\"Finished running 'retrieve':\"\n",
      "'\\n---\\n'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "\"Finished running 'grade_documents':\"\n",
      "'\\n---\\n'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "\"Finished running 'generate':\"\n",
      "'\\n---\\n'\n",
      "Generation:\n",
      "According to Amazon's 2022 Sustainability Report, the company's goals regarding waste and circularity include:\n",
      "\n",
      "1. Eliminating waste across Amazon's own operations, as well as throughout its supply chain and customer areas. (Source: 2022-sustainability-report.pdf, Page: 33)\n",
      "2. Scaling waste reduction and product circularity programs across Amazon's own operations, as well as throughout its supply chain and customer areas. (Source: 2022-sustainability-report.pdf, Page: 33)\n",
      "3. Helping customers sustainably use the items they buy from Amazon by offering repair, refurbishment, resale, and recycling options. (Source: 2022-sustainability-report.pdf, Page: 32)\n",
      "4. Innovating more ways for customers to shop for sustainable products and responsibly manage the packaging in which their items are delivered. (Source: 2022-sustainability-report.pdf, Page: 32)\n",
      "\n",
      "Amazon is also partnering with the Circular Economy for Flexible Packaging industry consortium and Waste and Resources Action Programme (WRAP) on a recycling initiative to leverage their expertise and industry network, as well as Amazon's technology and innovation, to deliver increasingly effective recycling solutions. (Source: 2022-sustainability-report.pdf, Page: 33)\n",
      "\n",
      "Citations:\n",
      "- 2022-sustainability-report.pdf, Page: 34\n",
      "- 2022-sustainability-report.pdf, Page: 34\n",
      "- 2022-sustainability-report.pdf, Page: 34\n",
      "- 2022-sustainability-report.pdf, Page: 33\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"What are Amazon's goals regarding Waste and Circularity?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running '{key}':\")\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "print(\"Generation:\")\n",
    "print(value[\"generation\"])\n",
    "print(\"\\nCitations:\")\n",
    "for citation in value[\"citations\"]:\n",
    "    print(f\"- {citation['source']}, Page: {citation['page']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T14:56:25.092955Z",
     "start_time": "2024-06-24T14:56:19.565776Z"
    }
   },
   "id": "9f04a3d3db03100e",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "\"Finished running 'retrieve':\"\n",
      "'\\n---\\n'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "\"Finished running 'grade_documents':\"\n",
      "'\\n---\\n'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "\"Finished running 'generate':\"\n",
      "'\\n---\\n'\n",
      "Generation:\n",
      "Amazon is helping its employees upskill through various initiatives. According to the 2022 Sustainability Report, Amazon invested $1 billion to upskill over 100,000 U.S. employees. Additionally, the company provides free skills training to over 10 million people globally, aiming to equip them with the skills needed to succeed in the modern workforce.\n",
      "\n",
      "Amazon's Future Engineer program is another example of the company's efforts to upskill its employees. The program provides students with skills training, professional certificates, language learning, and college degrees. As of 2022, the program has reached over 1.9 million students in the U.S. and globally.\n",
      "\n",
      "Furthermore, Amazon's Whole Planet Foundation has granted microloans to over 33,000 entrepreneurs, providing them with the necessary capital to start or grow their businesses. This initiative not only helps entrepreneurs but also creates job opportunities and stimulates local economies.\n",
      "\n",
      "Overall, Amazon's upskilling initiatives aim to empower its employees and the broader community with the skills and knowledge needed to succeed in the modern workforce.\n",
      "\n",
      "Citations:\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"How is Amazon helping in upskilling their employees?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running '{key}':\")\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "print(\"Generation:\")\n",
    "print(value[\"generation\"])\n",
    "print(\"\\nCitations:\")\n",
    "for citation in value[\"citations\"]:\n",
    "    print(f\"- {citation['source']}, Page: {citation['page']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T14:56:54.011832Z",
     "start_time": "2024-06-24T14:56:25.094111Z"
    }
   },
   "id": "63cb5c0bcdc43607",
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
